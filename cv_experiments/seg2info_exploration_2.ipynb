{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation to Information Exploration 2\n",
    "Last time (in `seg2info_exploration.ipynb`), we figured out the transformations necessary to get from a semantically segmented camera image to a map in real (log-polar) coordinates. Here, we'll focus on putting those routines into a Python module and on performing interpolation better to reduce fringe-type artifacts at high distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put the reusable routines in `cv_experiments.seg2info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv_experiments.seg2info as s2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We'll start by loading the same data as in part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = s2i.load_dirs(\"../representatives/segmentation/seginput\", \"../arctic_images_original_2/segmaps\")\n",
    "names = [image[\"name\"] for image in images]\n",
    "print(names)\n",
    "s2i.plot_all(images, s2i.simple_composite, lambda fig: fig.subplots_adjust(hspace=-0.5))\n",
    "s2i.plot_all(images, s2i.plot_mask, lambda fig: fig.subplots_adjust(hspace=-0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical to continuous\n",
    "Our main strategy here will be to allocate one floating-point channel for each of the possible integer values in the mask. Initially this will be a one-hot encoding, but as we perform all the transformations, interpolation will give rise to fractional values representing \"iciness,\" \"skyness,\" etc. Then, if desired, we can apply an argmax or something at the end to get back to discrete data. For now, we'll visualize this data structure as an RGB image where green is iciness, blue is wateriness, and red is everything else-iness.\n",
    "\n",
    "A small complication: certain OpenCV things don't like images with more than four channels, so instead of a full one-hot encoding, we'll just use the four channels water, sky, ice, and rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.one_hot_four, images, \"segmap\", \"segcont\")\n",
    "s2i.plot_key(images, \"segcont\", lambda fig: fig.subplots_adjust(hspace=-0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also upscale the images so the transformations to follow are less lossy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.upscale, images, \"segcont\", \"upscaled\")\n",
    "print(images[0][\"upscaled\"].shape)\n",
    "s2i.plot_key(images, \"upscaled\", lambda fig: fig.subplots_adjust(hspace=-0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go through the existing pipeline, just with interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undistortion and horizon finding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.undistort, images, \"upscaled\", \"undistorted\")\n",
    "s2i.apply(s2i.find_horizon, images, \"undistorted\", \"horizon\")\n",
    "s2i.plot_all(images, lambda ax,img: s2i.plot_line(ax, img, \"undistorted\", \"horizon\"), lambda fig: fig.subplots_adjust(hspace=-0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotating, adjusting, and cropping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.rotate_image, images, [\"undistorted\", \"horizon\"], [\"rotated\", \"rot_scale\", \"orig_height\"])\n",
    "s2i.apply(s2i.adjust_and_crop, images, [\"rotated\", \"horizon\", \"orig_height\"], \"adjusted\")\n",
    "s2i.plot_key(images, \"adjusted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinate transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.camera_to_log_polar, images, [\"adjusted\", \"rot_scale\", \"orig_height\"], \"logpolar\")\n",
    "s2i.plot_all(images, s2i.plot_log_polar, lambda fig: fig.subplots_adjust(hspace=-0.5, wspace=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we're back where we were. Slightly better results due to the interpolation, but we've still got some issues. How about a blur right before the coordinate transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "kernel = [s2i.upscale_factor*4+1, s2i.upscale_factor*2+1]\n",
    "s2i.apply(lambda img: cv2.blur(img, kernel), images, \"adjusted\", \"blurred\")\n",
    "s2i.plot_key(images, \"blurred\")\n",
    "s2i.apply(s2i.camera_to_log_polar, images, [\"blurred\", \"rot_scale\", \"orig_height\"], \"logpolar-2\")\n",
    "s2i.plot_all(images, lambda ax,img: s2i.plot_log_polar(ax, img, \"logpolar-2\"), lambda fig: fig.subplots_adjust(hspace=-0.5, wspace=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, looks like we really have to sacrifice image quality to get blurring to reduce the fringing much. More ideas: erode/dilate the ice in the original image? Resize using deep learning fanciness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the whole process here where we can mess with it, and then try a few things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def horizon_blur(img, orig_height, horizon_height=s2i.upscale_factor*s2i.sky_buffer):\n",
    "    img = cv2.blur(img, (s2i.upscale_factor*3, s2i.upscale_factor*3))\n",
    "    res = img.copy()\n",
    "    x = np.arange(s2i.upscale_factor*5, -1, -1)\n",
    "    y = (x[0]-x)*50/x[0]+3\n",
    "    x += horizon_height\n",
    "    for i, (blur_height, blur_radius) in enumerate(zip(x, y)):\n",
    "        if blur_radius < 1: continue\n",
    "        res[:int(blur_height),:] = cv2.blur(img[:int(blur_height),:], (int(blur_radius), int(blur_radius*0.05+1)))\n",
    "    return res\n",
    "\n",
    "def whole_pipeline(img):\n",
    "    interpolation_method = cv2.INTER_CUBIC\n",
    "    img = s2i.one_hot_four(img)\n",
    "    img = s2i.upscale(img, interpolation_method=interpolation_method)\n",
    "    img = s2i.undistort(img, interpolation_method=interpolation_method)\n",
    "    horizon = s2i.find_horizon(img)\n",
    "    img, scale, height = s2i.rotate_image(img, horizon, interpolation_method=interpolation_method)\n",
    "    img = s2i.adjust_and_crop(img, horizon, height, interpolation_method=interpolation_method)\n",
    "    img = horizon_blur(img, height)\n",
    "    img = horizon_blur(img, height)  # Repetition intentional\n",
    "    img = s2i.camera_to_log_polar(img, scale, height, interpolation_method=interpolation_method)\n",
    "    return img\n",
    "\n",
    "s2i.apply(whole_pipeline, images, \"segmap\", \"logpolar-3\")\n",
    "s2i.plot_all(images, lambda ax,img: s2i.plot_log_polar(ax, img, \"logpolar-3\"), lambda fig: fig.subplots_adjust(hspace=-0.5, wspace=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's somewhat better. Now let's convert to a single channel \"iciness\" map where lack of data is represented by `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.four_to_one, images, \"logpolar-3\", \"single_out\")\n",
    "s2i.plot_all(images, lambda ax,img: s2i.plot_log_polar(ax, img, \"single_out\"), lambda fig: fig.subplots_adjust(hspace=-0.5, wspace=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.whole_pipeline, images, \"segmap\", \"logpolar_final\")\n",
    "s2i.plot_all(images, lambda ax,img: s2i.plot_log_polar(ax, img, \"logpolar_final\"), lambda fig: fig.subplots_adjust(hspace=-0.5, wspace=0.4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('NOAA-new4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f23bc15fa2a9b8265d1e51794e99855102cbc7e23f98bc87a194261d0b0c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
