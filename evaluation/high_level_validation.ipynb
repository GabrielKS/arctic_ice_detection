{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level Validation\n",
    "Let's calculate some statistics about the predictions we've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(\"../saved_models/validlist_2022-08-01T23-30-48.txt\") as validfile:\n",
    "    validset = {os.path.splitext(f)[0] for f in validfile.read().splitlines()}\n",
    "\n",
    "preds_root = \"../cached/first_predicted\"\n",
    "actuals_root = \"../cached/first_ground\"\n",
    "preds = [pickle.load(open(os.path.join(preds_root, path), \"rb\")) for path in sorted(os.listdir(preds_root))\n",
    "    if path.endswith(\".pkl\") and os.path.splitext(path)[0] in validset]\n",
    "actuals = [pickle.load(open(os.path.join(actuals_root, path), \"rb\")) for path in sorted(os.listdir(actuals_root))\n",
    "    if path.endswith(\".pkl\") and os.path.splitext(path)[0] in validset]\n",
    "\n",
    "print(len(preds))\n",
    "print(len(actuals))\n",
    "\n",
    "assert all(p[0][\"name\"] == p[1][\"name\"] for p in zip(preds, actuals))\n",
    "print(actuals[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "hl_df_dict = {}\n",
    "def add_both(name, accessor):\n",
    "    hl_df_dict[\"pred_\"+name] = [accessor(pred) for pred in preds]\n",
    "    hl_df_dict[\"actual_\"+name] = [accessor(actual) for actual in actuals]\n",
    "add_both(\"intercept\", lambda row: (*row[\"horizon\"],)[0])  # Hey turns out it _was_ iterable\n",
    "add_both(\"slope\", lambda row: (*row[\"horizon\"],)[1])\n",
    "add_both(\"ice_amount\", lambda row: row[\"ice_amount\"])\n",
    "add_both(\"closest_ice\", lambda row: row[\"closest_ice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_experiments.seg2info import Seg2Info\n",
    "s2i = Seg2Info()\n",
    "import numpy as np\n",
    "\n",
    "logb = s2i.proc_props[\"logb\"]\n",
    "far = s2i.cam_props[\"horizon_distance\"]\n",
    "near = s2i.cam_props[\"near_distance\"]\n",
    "\n",
    "log_dist = lambda dists: logb(np.where(dists > far, far, dists))\n",
    "add_both(\"log_closest_ice\", lambda row: log_dist(row[\"closest_ice\"]))\n",
    "hl_df = pd.DataFrame(hl_df_dict)\n",
    "display(hl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_linear(name=None, format_1=\"\", format_2=\"\", actual=None, pred=None):\n",
    "    if actual is None: actual = hl_df[f'actual_{name}']\n",
    "    if pred is None: pred = hl_df[f'pred_{name}']\n",
    "    print(f\"Mean actual {name}: {actual.mean():{format_1}}\")\n",
    "    print(f\"Mean predicted {name}: {pred.mean():{format_1}}\")\n",
    "    print(f\"SD actual {name}: {(sd := actual.std()):{format_2}}\")\n",
    "    print(f\"SD predicted {name}: {pred.std():{format_2}}\")\n",
    "    print(f\"RMSE {name}: {(rmse := ((pred-actual) ** 2).mean() ** 0.5):{format_1}}\")\n",
    "    print(f\"RMSE is {rmse/sd:.2%} of SD for {name}\")\n",
    "    print()\n",
    "eval_linear(\"slope\", \".2E\", \".3f\")\n",
    "eval_linear(\"intercept\", \".1f\", \".1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now let's evaluate the actual output metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moderate_mask = (hl_df[\"actual_closest_ice\"] > near) & (hl_df[\"actual_closest_ice\"] < far) & (hl_df[\"pred_closest_ice\"] > near) & (hl_df[\"pred_closest_ice\"] < far)\n",
    "moderate_mask = (hl_df[\"actual_closest_ice\"] < float(\"inf\")) & (hl_df[\"pred_closest_ice\"] < float(\"inf\"))\n",
    "filter_moderate = lambda data_key: hl_df[moderate_mask][data_key]\n",
    "\n",
    "eval_linear(\"ice_amount\", \".3f\", \".3f\")\n",
    "eval_linear(\"log_closest_ice\", \".3f\", \".3f\")\n",
    "eval_linear(\"log_closest_ice_moderate\", \".3f\", \".3f\", filter_moderate(\"actual_log_closest_ice\"), filter_moderate(\"pred_log_closest_ice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('NOAA-new4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f23bc15fa2a9b8265d1e51794e99855102cbc7e23f98bc87a194261d0b0c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
