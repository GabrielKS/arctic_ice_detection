{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to compare the distances output by our algorithm to some known distances to try to validate the former. We'll start with the series of images presented in Figure 9 of _Chiodi et al., 2021_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cv_experiments.seg2info import Seg2Info\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "s2i = Seg2Info(output_props={\"width\": 1920, \"height\": 1072})\n",
    "\n",
    "images = s2i.load_dirs(\"../validation/fig9_seginput\", \"../validation/fig9_segmaps\")\n",
    "images = images[:9]  # The images after this are just the boat being stuck in ice\n",
    "def fig9title(image):\n",
    "    dt = datetime.fromtimestamp(int(image['name'].split('.')[0].split('_')[2]), tz=timezone.utc)\n",
    "    return f\"{dt:%H:%M:%S}\"\n",
    "print([image[\"name\"] for image in images])\n",
    "print(images[0][\"segmap\"].shape)\n",
    "s2i.plot_all(images, lambda ax, image: s2i.simple_composite(ax, image, title=fig9title(image)), lambda fig: fig.subplots_adjust(hspace=-0.5))\n",
    "s2i.plot_all(images, lambda ax, image: s2i.plot_mask(ax, image, title=fig9title(image)), lambda fig: fig.subplots_adjust(hspace=-0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted to log-polar, that's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i.apply(s2i.whole_pipeline, images, \"segmap\", \"logpolar_final\")\n",
    "s2i.plot_all(images, lambda ax, image: s2i.plot_log_polar(ax, image, \"logpolar_final\", title=fig9title(image)), lambda fig: fig.subplots_adjust(hspace=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that the boat gets stuck in the ice at around 00:39:30, which lets us estimate the ice's velocity by the boat's speed over the next few minutes while it is stuck in the ice. Then, we can extrapolate backwards to find the ice's position at a given time (assuming it moves at constant velocity), which lets us calculate the distance from the boat to the ice for the sequence of images above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a table of lat/lons for the image timestamps, a table of speeds and headings while stuck in ice, an estimate of the collision time, and a known ice lat/lon and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "latlon_data = pd.read_csv(\"../validation/fig9_latlons.csv\", index_col=\"time\")\n",
    "stuck_data = pd.read_csv(\"../validation/fig9_stuck_SOG_COG.csv\", index_col=\"time\")\n",
    "params_data = pd.read_csv(\"../validation/fig9_params.csv\", index_col=\"key\")\n",
    "display(latlon_data)\n",
    "display(stuck_data)\n",
    "display(params_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, time for some math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Interesting discussion at https://math.stackexchange.com/questions/3321142/how-to-compute-the-average-in-modular-arithmetic\n",
    "def modular_avg(data, mod):\n",
    "    TAU = 2*np.pi\n",
    "    remapped = data*TAU/mod\n",
    "    points = np.array([np.sin(remapped), np.cos(remapped)])\n",
    "    avg_yx = points.mean(axis=1)\n",
    "    mag = np.hypot(*avg_yx)\n",
    "    if mag < 0.5: print(f\"Modular average risks being meaningless (magnitude={mag})\")\n",
    "    result = np.arctan2(*avg_yx)*mod/TAU\n",
    "    return result\n",
    "\n",
    "def polar_to_vector(mag, angle_deg):\n",
    "    \"\"\"Convert a magnitude and an angle in degrees (measured clockwise with 0 as north) to an x,y vector\"\"\"\n",
    "    angle_rad = -np.deg2rad(angle_deg)+np.pi/2  # Compass to unit circle\n",
    "    uv = np.array([np.cos(angle_rad), np.sin(angle_rad)])\n",
    "    return uv*mag\n",
    "\n",
    "def sog_cog_to_ms(sog_kts, cog_deg):\n",
    "    \"\"\" Convert speed over ground in knots and course over ground in degrees to an x,y vector in m/s\n",
    "    :param sog_kts: speed over ground in knots\n",
    "    :param cog_deg: course over ground in degrees, measured clockwise with 0 as north\n",
    "    :returns: an x,y vector in m/s where +x is east, +y is north\n",
    "    \"\"\"\n",
    "    MS_PER_KT = 0.514\n",
    "    return polar_to_vector(sog_kts*MS_PER_KT, cog_deg)\n",
    "\n",
    "def latlon_offset_to_m(src_latlon, dest_latlon):\n",
    "    \"\"\" Find a vector representing the shortest path over the Earth from the source lat/lon to the destination lat/lon\n",
    "    :param src_latlon: a lat,lon pair representing the source\n",
    "    :param dest_latlon: a lat,lon pair representing the destination\n",
    "    :returns: an x,y vector in meters where +x is east, +y is north\n",
    "    \"\"\"\n",
    "\n",
    "    geod = Geodesic.WGS84\n",
    "    path = geod.Inverse(*src_latlon, *dest_latlon)\n",
    "    dist = path[\"s12\"]\n",
    "    # We are given two azimuths of the line: one from the perspective of the start point and one the end point\n",
    "    # Let's just average them\n",
    "    course = np.mean([path[\"azi1\"], path[\"azi2\"]])\n",
    "    return polar_to_vector(dist, course)\n",
    "\n",
    "origin_lat_lon = np.array([params_data[\"value\"][\"lat_basis\"], params_data[\"value\"][\"lon_basis\"]])\n",
    "origin_time = params_data[\"value\"][\"t_basis\"]\n",
    "\n",
    "avg_ice_speed = stuck_data[\"LTF SOG\"].mean()\n",
    "avg_ice_course = modular_avg(stuck_data[\"LTF COG\"], 360)\n",
    "ice_vector = sog_cog_to_ms(avg_ice_speed, avg_ice_course)\n",
    "\n",
    "times = np.array(latlon_data.index)\n",
    "ice_positions = np.outer((times-origin_time)*60, ice_vector)\n",
    "boat_positions = np.array([latlon_offset_to_m(origin_lat_lon, x[1].values)\n",
    "    for x in latlon_data[[\"lat\", \"lon\"]].iterrows()])\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.gca().axis(\"equal\")\n",
    "plt.plot(*(ice_positions.T))\n",
    "plt.plot(*(boat_positions.T))\n",
    "plt.show()\n",
    "\n",
    "distances = np.hypot(*(ice_positions-boat_positions).T)\n",
    "plt.scatter(times, distances)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is… okay, but it strikes us now that it might be both simpler and more accurate to bypass speed measurements altogether and just pick a pair of points to extrapolate based on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_data = pd.read_csv(\"../validation/fig9_ice_refs.csv\", index_col=\"time\")\n",
    "display(ice_data)\n",
    "ice_vector = latlon_offset_to_m(ice_data.iloc[0][[\"lat\", \"lon\"]].values, ice_data.iloc[1][[\"lat\", \"lon\"]].values)/((ice_data.index[1]-ice_data.index[0])*60)\n",
    "origin_lat_lon = ice_data.iloc[0][[\"lat\", \"lon\"]].values\n",
    "origin_time = ice_data.index[0]\n",
    "\n",
    "ice_positions = np.outer((times-origin_time)*60, ice_vector)\n",
    "boat_positions = np.array([latlon_offset_to_m(origin_lat_lon, x[1].values)\n",
    "    for x in latlon_data[[\"lat\", \"lon\"]].iterrows()])\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.gca().axis(\"equal\")\n",
    "plt.plot(*(ice_positions.T))\n",
    "plt.plot(*(boat_positions.T))\n",
    "# plt.scatter(0, 0)\n",
    "plt.show()\n",
    "\n",
    "distances = np.hypot(*(ice_positions-boat_positions).T)\n",
    "plt.scatter(times, distances)\n",
    "print(np.stack([times, distances]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we get quite different values depending on whether we account for ice movement or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_naive = np.hypot(*(boat_positions).T)\n",
    "plt.scatter(times, distances_naive, label=\"Without ice movement\")\n",
    "plt.scatter(times, distances, label=\"With ice movement\")\n",
    "plt.legend()\n",
    "\n",
    "summary_table = pd.DataFrame({\"time\": times, \"no_ice_mvt\": distances_naive, \"yes_ice_mvt\": distances}).set_index(\"time\")\n",
    "with pd.option_context(\"display.precision\", 2): display(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's figure out what our images are telling us about the distance to the closest ice. Roughly, we will calculate the fraction of the field of view that is ice at every distance increment and report the closest one that has more than, say, 5% ice coverage. This rules out little \"outlier\" chunks of ice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_ice(logpolar_plot, ice_thresh=0.05, nan_thresh=0.1):\n",
    "    num = np.nansum(logpolar_plot, axis=1)\n",
    "    n_nonnan = (~np.isnan(logpolar_plot)).sum(axis=1)\n",
    "    frac_ice = np.where(n_nonnan/logpolar_plot.shape[1] > nan_thresh, np.divide(num, n_nonnan, where=(n_nonnan != 0)), np.nan)\n",
    "    is_ice = frac_ice > ice_thresh\n",
    "    i_last = logpolar_plot.shape[0]-np.argmax(is_ice[::-1])-1\n",
    "    dist_last = s2i.y2dist(i_last)\n",
    "    return dist_last\n",
    "\n",
    "summary_table[\"camera_predicted\"] = s2i.apply(closest_ice, images, \"logpolar_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.precision\", 2): display(summary_table)\n",
    "plt.scatter(times, distances_naive, label=\"Without ice movement\")\n",
    "plt.scatter(times, distances, label=\"With ice movement\")\n",
    "plt.scatter(times, summary_table[\"camera_predicted\"], label=\"Camera predicted nearest\")\n",
    "plt.xlabel(\"Minutes after the hour\")\n",
    "plt.ylabel(\"Distance to ice (m)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a first glance… nope, it doesn't work.\n",
    "\n",
    "However, there are many potential confounding factors:\n",
    " 1. Up until the image around 00:38, the ice is really just a thin line on the horizon. As expected, the predictions are much better at close range.\n",
    " 2. We are getting the distance to the closest part of the ice edge, not the distance to the part we are actually heading towards. The expected effect of this factor is to produce an underestimation, which is what we observe.\n",
    " 3. We are relying quite a bit on the assumption that the ice moves at a constant velocity (as illustrated by the difference between the predictions with and without ice movement).\n",
    "\n",
    "How can we do better?\n",
    " 1. We can restrict our domain to the set of images actually used in the paper, taking out some of the ones where the ice is farthest away.\n",
    " 2. We can try to calculate the angle to the part of the ice edge we're actually headed towards and get only this distance.\n",
    " 3. I can't think of any way to address #3 other than by setting up a controlled trial (which certainly should be done in the future)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, though, let's do a deep dive into perhaps the most informative image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "key_i = 6\n",
    "key_image = images[key_i]\n",
    "fig,axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "fig.suptitle(fig9title(key_image))\n",
    "axs[0].imshow(cv2.cvtColor(key_image[\"seginput\"], cv2.COLOR_BGR2RGB))\n",
    "s2i.plot_mask(axs[1], key_image, title=\"\")\n",
    "s2i.plot_log_polar(axs[2], key_image, \"logpolar_final\", title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image-predicted distance to closest ice is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_values = {}\n",
    "key_values[\"img_closest\"] = closest_ice(key_image['logpolar_final'])\n",
    "print(f\"{key_values['img_closest']:.2f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the image-predicted distance to farthest water (i.e., the maximum distance to ice)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_water(logpolar_plot, water_thresh=0.95, nan_thresh=0.1):\n",
    "    num = np.nansum(logpolar_plot, axis=1)\n",
    "    n_nonnan = (~np.isnan(logpolar_plot)).sum(axis=1)\n",
    "    frac_ice = np.where(n_nonnan/logpolar_plot.shape[1] > nan_thresh, np.divide(num, n_nonnan, where=(n_nonnan != 0)), np.nan)\n",
    "    frac_ice = np.fmax.accumulate(frac_ice[::-1])[::-1]  # Enforce monotonicity: if there's water behind a complete wall of ice, it doesn't count\n",
    "    is_water = frac_ice <= water_thresh\n",
    "    i_first = np.argmax(is_water)\n",
    "    dist_first = s2i.y2dist(i_first)\n",
    "    return dist_first\n",
    "\n",
    "key_values[\"img_farthest\"] = farthest_water(key_image['logpolar_final'])\n",
    "print(f\"{key_values['img_farthest']:.2f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So regardless of confounding factor #2, we would expect the actual distance to ice to be within that range. However, the \"actual\" distance to ice, as best as we can calculate it from our position data, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_table[[\"no_ice_mvt\", \"yes_ice_mvt\"]].iloc[key_i])\n",
    "key_values[\"no_ice_mvt\"] = summary_table[\"no_ice_mvt\"].iloc[key_i]\n",
    "key_values[\"yes_ice_mvt\"] = summary_table[\"yes_ice_mvt\"].iloc[key_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another datapoint: just eyeballing it, I'd say the maximum distance to ice looks to be roughly `60` meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more sanity check: let's do a ballpark trig estimate of the ice distances. I measure the closest ice to be roughly `105` pixels down from the horizon, and the farthest water `29` pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_px_down_to_dist = lambda px, height=key_image['logpolar_final'].shape[0]: \\\n",
    "    np.tan(np.arctan(s2i.cam_props[\"horizon_distance\"]/s2i.cam_props[\"camera_height\"]) -\n",
    "        np.deg2rad((s2i.cam_props[\"vert_fov\"]*s2i.cam_props[\"dist_factor\"])*px/height))*s2i.cam_props[\"camera_height\"]\n",
    "\n",
    "key_values[\"trig_closest\"] = key_px_down_to_dist(105)\n",
    "key_values[\"trig_farthest\"] = key_px_down_to_dist(29)\n",
    "print(f\"Closest distance: {key_values['trig_closest']:.2f}m\")\n",
    "print(f\"Farthest distance: {key_values['trig_farthest']:.2f}m\")\n",
    "print(key_px_down_to_dist(images[0][\"segmap\"].shape[0]))\n",
    "print(s2i.cam_props[\"near_distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context(\"display.precision\", 2): display(pd.DataFrame.from_dict(key_values, orient=\"index\"))\n",
    "plt.figure(figsize=(10,4))\n",
    "bars = plt.bar(key_values.keys(), key_values.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is going on here?\n",
    " * `yes_ice_mvt` seems to be an overestimate\n",
    " * We seem to be heading towards not the closest ice\n",
    " * The manual trig estimates are still somewhat higher than the automatic image estimates. Why?\n",
    "\n",
    "Okay, so we still have some puzzling results, but the algorithm doesn't look *quite* so bad anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the previous image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2_i = 5\n",
    "key2_image = images[key2_i]\n",
    "fig,axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "fig.suptitle(fig9title(key2_image))\n",
    "axs[0].imshow(cv2.cvtColor(key2_image[\"seginput\"], cv2.COLOR_BGR2RGB))\n",
    "s2i.plot_mask(axs[1], key2_image, title=\"\")\n",
    "s2i.plot_log_polar(axs[2], key2_image, \"logpolar_final\", title=\"\")\n",
    "key2_values = {}\n",
    "key2_values[\"img_closest\"] = closest_ice(key2_image['logpolar_final'])\n",
    "print(f\"{key2_values['img_closest']:.2f}m\")\n",
    "key2_values[\"img_farthest\"] = farthest_water(key2_image['logpolar_final'])\n",
    "print(f\"{key2_values['img_farthest']:.2f}m\")\n",
    "print(summary_table[[\"no_ice_mvt\", \"yes_ice_mvt\"]].iloc[key2_i])\n",
    "key2_values[\"no_ice_mvt\"] = summary_table[\"no_ice_mvt\"].iloc[key2_i]\n",
    "key2_values[\"yes_ice_mvt\"] = summary_table[\"yes_ice_mvt\"].iloc[key2_i]\n",
    "key2_values[\"trig_closest\"] = key_px_down_to_dist(11, key2_image['logpolar_final'].shape[0])\n",
    "key2_values[\"trig_farthest\"] = key_px_down_to_dist(0)\n",
    "print(f\"Closest distance: {key2_values['trig_closest']:.2f}m\")\n",
    "print(f\"Farthest distance: {key2_values['trig_farthest']:.2f}m\")\n",
    "plt.figure(figsize=(10,4))\n",
    "bars = plt.bar(key2_values.keys(), key2_values.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Committing for the historical record because this is the version I used for my presentation, but when I went to clean up and commit this code I realized there's something weird going on with `farthest_water` that TODO I should investigate. In any case, we need more controlled data to really well validate the algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('NOAA-new4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f23bc15fa2a9b8265d1e51794e99855102cbc7e23f98bc87a194261d0b0c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
